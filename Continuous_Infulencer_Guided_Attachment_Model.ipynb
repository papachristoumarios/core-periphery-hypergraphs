{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Continuous Infulencer Guided Attachment Model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "mount_file_id": "14dwdWjqFKIK6jzutJSs8KDf_q7uilsw6",
      "authorship_tag": "ABX9TyNqdNT1UPzt51JkIKTnCasy",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/papachristoumarios/core-periphery-latent-model/blob/main/Continuous_Infulencer_Guided_Attachment_Model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_Uv1_15iBt6"
      },
      "source": [
        "<center>\n",
        "\n",
        "<h1>Continuous Influencer Attachment Model: Supplementary Code</h1>\n",
        "<p>Marios Papachristou (papachristoumarios@cs.cornell.edu)</p>\n",
        "<p>Jon Kleinberg (kleinberg@cs.cornell.edu)</p>\n",
        "\n",
        "</center>\n",
        "\n",
        "## Dependencies\n",
        "\n",
        "We install the following dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZgmp7UHh_FH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6d8ac29-0fd0-4961-9502-50c99e5ce538"
      },
      "source": [
        "!pip install hypernetx --quiet\n",
        "!pip install pystan --quiet\n",
        "!pip install arviz --quiet\n",
        "!pip install karateclub"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: karateclub in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: pygsp in /usr/local/lib/python3.7/dist-packages (from karateclub) (0.5.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from karateclub) (0.22.2.post1)\n",
            "Requirement already satisfied: python-louvain in /usr/local/lib/python3.7/dist-packages (from karateclub) (0.15)\n",
            "Requirement already satisfied: decorator==4.4.2 in /usr/local/lib/python3.7/dist-packages (from karateclub) (4.4.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from karateclub) (4.41.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from karateclub) (1.4.1)\n",
            "Requirement already satisfied: gensim>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from karateclub) (4.0.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from karateclub) (2.5.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from karateclub) (1.15.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from karateclub) (1.1.5)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from karateclub) (1.19.5)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->karateclub) (1.0.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.7/dist-packages (from gensim>=4.0.0->karateclub) (5.1.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->karateclub) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->karateclub) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bz8h08XJh769"
      },
      "source": [
        "## Imports\n",
        "\n",
        "We perform the following imports in our python environment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fXe2WF5lzjx2",
        "outputId": "9f44b575-16bf-4b30-ba1a-a38deb28321e"
      },
      "source": [
        "import scipy.io\n",
        "import os\n",
        "import copy\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import networkx as nx\n",
        "import collections\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import matplotlib\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "import random\n",
        "import itertools\n",
        "import pystan\n",
        "import pickle\n",
        "import arviz as az\n",
        "from sklearn import linear_model\n",
        "from scipy.optimize import minimize\n",
        "from scipy import stats\n",
        "\n",
        "sns.set_theme()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szmU6eWFzY9m"
      },
      "source": [
        "## Dataloaders\n",
        "\n",
        "We define the dataloaders below"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1OXLA0Nzh-_"
      },
      "source": [
        "def stanfit_to_dataframe(fit):\n",
        "  return pd.DataFrame.from_dict(data=fit.extract())\n",
        "\n",
        "def load_world_trade(location='/content/drive/My Drive/NNIM/data/world-trade/world-trade.csv'):\n",
        "  df = pd.read_csv(location)\n",
        "  G = nx.convert_matrix.from_pandas_edgelist(df, source='from', target='to')\n",
        "  return G\n",
        "\n",
        "def load_faculty(location='/content/drive/My Drive/NNIM/data/faculty/ComputerScience_edgelist.txt'):\n",
        "  df = pd.read_csv(location, sep='\\t')\n",
        "  G = nx.convert_matrix.from_pandas_edgelist(df, source='# u', target='v')\n",
        "  vertexlist_filename = location.replace('edgelist', 'vertexlist')\n",
        "  vertex_df = pd.read_csv(vertexlist_filename, sep='\\t')\n",
        "  vertex_df.set_index('# u', inplace=True)\n",
        "  mapping = vertex_df['institution'].to_dict()\n",
        "  nx.set_node_attributes(G, mapping, 'name')\n",
        "\n",
        "  return G\n",
        "\n",
        "def load_polblogs(location='/content/drive/My Drive/NNIM/data/polblogs/polblogs.mtx'):\n",
        "  df = pd.read_csv(location, sep=' ', comment='%', header=None)\n",
        "  G = nx.convert_matrix.from_pandas_edgelist(df, source=0, target=1)\n",
        "  return G\n",
        "\n",
        "def load_airports(location='/content/drive/My Drive/NNIM/data/airports/USairport500.txt'):\n",
        "  df = pd.read_csv(location, sep=' ', header=None)\n",
        "  G = nx.convert_matrix.from_pandas_edgelist(df, source=0, target=1)\n",
        "  return G\n",
        "\n",
        "def load_celegans(location='/content/drive/My Drive/NNIM/data/celegans', relabel=True):\n",
        "  A = np.genfromtxt(os.path.join(location, 'celegans_matrix.csv'), delimiter=',', dtype=np.int64).astype(np.int64)\n",
        "  locs = np.genfromtxt(os.path.join(location, 'celegans_positions.csv'), delimiter=',').astype(np.float64)\n",
        "  mapping = {}\n",
        "  for i, loc in enumerate(locs):\n",
        "    mapping[i] = loc\n",
        "\n",
        "  G = nx.from_numpy_array(A)\n",
        "\n",
        "  Gccs = sorted(nx.connected_components(G), key=len, reverse=True)\n",
        "  G = G.subgraph(Gccs[0])\n",
        "\n",
        "  nx.set_node_attributes(G, mapping, \"location\")\n",
        "\n",
        "  if relabel:\n",
        "    G = nx.convert_node_labels_to_integers(G)\n",
        "\n",
        "  return G\n",
        "\n",
        "def load_london_underground(location='/content/drive/My Drive/NNIM/data/london_underground', relabel=True):\n",
        "  A = np.genfromtxt(os.path.join(location, 'london_underground_network.csv'), delimiter=',', dtype=np.int64).astype(np.int64)\n",
        "  locs = np.genfromtxt(os.path.join(location, 'london_underground_tubes.csv'), delimiter=',').astype(np.float64)\n",
        "  names = np.genfromtxt(os.path.join(location, 'london_underground_names.csv'), delimiter='\\t', dtype=str)\n",
        "\n",
        "  mapping = {}\n",
        "  for i, loc in enumerate(locs):\n",
        "    mapping[i] = loc\n",
        "\n",
        "  names_mapping = {}\n",
        "  for i, name in enumerate(names):\n",
        "    names_mapping[i] = name\n",
        "\n",
        "  G = nx.from_numpy_array(A)\n",
        "\n",
        "  Gccs = sorted(nx.connected_components(G), key=len, reverse=True)\n",
        "  G = G.subgraph(Gccs[0])\n",
        "\n",
        "  nx.set_node_attributes(G, mapping, \"location\")\n",
        "  nx.set_node_attributes(G, names_mapping, \"name\")\n",
        "\n",
        "  if relabel:\n",
        "    G = nx.convert_node_labels_to_integers(G)\n",
        "\n",
        "  return G\n",
        "\n",
        "def load_open_airlines(location='/content/drive/My Drive/NNIM/data/open_airlines', relabel=True):\n",
        "  airports = pd.read_csv(os.path.join(location, 'airports.dat'), header=None).iloc[:, [4, 6, 7]]\n",
        "  routes = pd.read_csv(os.path.join(location, 'routes.dat'), header=None).iloc[:, [2, 4]]\n",
        "  G = nx.convert_matrix.from_pandas_edgelist(routes, source=2, target=4, create_using=nx.Graph)\n",
        "  Gccs = sorted(nx.connected_components(G), key=len, reverse=True)\n",
        "  G = G.subgraph(Gccs[0])\n",
        "  mapping = {}\n",
        "  for i, x in airports.iterrows():\n",
        "    if G.has_node(x[4]):\n",
        "      mapping[x[4]] = np.array([x[6], x[7]])\n",
        "\n",
        "  nx.set_node_attributes(G, mapping, \"location\")\n",
        "\n",
        "  if relabel:\n",
        "    G = nx.convert_node_labels_to_integers(G, label_attribute='name')\n",
        "\n",
        "  return G  \n",
        "\n",
        "def load_fungal(location='/content/drive/My Drive/NNIM/data/fungal_networks', fungus='Pv_M_I_U_N_42d_1.mat', relabel=True):\n",
        "  mat = scipy.io.loadmat(os.path.join(location, fungus))\n",
        "  G = nx.from_scipy_sparse_matrix(mat['A'], create_using=nx.Graph)\n",
        "  mapping = {}\n",
        "\n",
        "  for i in range(mat['coordinates'].shape[0]):\n",
        "      mapping[i] = mat['coordinates'][i]\n",
        "\n",
        "  nx.set_node_attributes(G, mapping, 'location')  \n",
        "  if relabel:\n",
        "    G = nx.convert_node_labels_to_integers(G)\n",
        "\n",
        "  return G\n",
        "\n",
        "class Simplex:\n",
        "\n",
        "  def __init__(self, nodes=[], timestamp=None):\n",
        "    self.nodes = nodes\n",
        "    self.timestamp = timestamp\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(nodes)\n",
        "\n",
        "  def add_node(self, node):\n",
        "    self.nodes.append(node)\n",
        "\n",
        "class Hypergraph:\n",
        "\n",
        "  def __init__(self):\n",
        "    self.nodes = collections.defaultdict(bool)\n",
        "    self.simplices = []\n",
        "    self.pointers = collections.defaultdict(list)\n",
        "    self.graph = nx.Graph()\n",
        "\n",
        "  def add_simplex_from_nodes(self, nodes, timestamp=None):\n",
        "    simplex = Simplex(nodes=nodes, timestamp=timestamp)\n",
        "    self.add_simplex(simplex)\n",
        "\n",
        "  def add_simplex(self, simplex):\n",
        "    self.simplices.append(simplex)\n",
        "    for node in simplex.nodes:\n",
        "      self.nodes[node] = True\n",
        "      self.pointers[node].append(len(self.simplices) - 1)\n",
        "    \n",
        "    for u in simplex.nodes:\n",
        "      for v in simplex.nodes:\n",
        "        if u != v:\n",
        "          self.graph.add_edge(u, v, timestamp=simplex.timestamp)\n",
        "\n",
        "  def simplex_neighbors(self, node):\n",
        "    for pointer in self.pointers[node]:\n",
        "      yield self.simplices[pointer]\n",
        "\n",
        "  def nodes(self):\n",
        "    for key in self.nodes:\n",
        "      yield key\n",
        "\n",
        "  def simplices_iter(self):\n",
        "    for simplex in self.simplices:\n",
        "      yield simplex\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.nodes)\n",
        "  \n",
        "  def num_simplices(self):\n",
        "    return len(self.simplices)\n",
        "\n",
        "  @staticmethod\n",
        "  def graph_to_hypergraph(G):\n",
        "    H = Hypergraph()\n",
        "    for (u, v) in G.edges():\n",
        "      smp = Simplex([u, v])\n",
        "      H.add_simplex(smp)\n",
        "\n",
        "    return H\n",
        "\n",
        "  def clique_decomposition(self):\n",
        "    G = nx.Graph()\n",
        "    for simplex in self.simplices:\n",
        "      for i in range(len(simplex.nodes)):\n",
        "        for j in range(i):\n",
        "          G.add_edge(simplex.nodes[i], simplex.nodes[j])\n",
        "\n",
        "    return G\n",
        "\n",
        "  def star_decomposition(self):\n",
        "    G = nx.Graph()\n",
        "    for simplex in self.simplices:\n",
        "      node_name = ','.join([str(node) for node in simplex.nodes])\n",
        "      for u in simplex.nodes:\n",
        "        G.add_edge(u, node_name)\n",
        "\n",
        "    return G\n",
        "        \n",
        "def load_hypergraph(name='email-Enron', location='/content/drive/My Drive/NNIM/data'):\n",
        "  nverts = np.genfromtxt(os.path.join(location, name, '{}-nverts.txt'.format(name)), delimiter=',', dtype=np.int64)\n",
        "  simplices = np.genfromtxt(os.path.join(location, name, '{}-simplices.txt'.format(name)), delimiter=',', dtype=np.int64)\n",
        "  times = np.genfromtxt(os.path.join(location, name, '{}-times.txt'.format(name)), delimiter=',', dtype=np.int64)\n",
        "\n",
        "  H = Hypergraph()\n",
        "  j = 0\n",
        "\n",
        "  for nvert, timestamp in zip(nverts, times):\n",
        "    simplex = Simplex([], timestamp)\n",
        "    for i in range(nvert):\n",
        "      simplex.add_node(simplices[j])\n",
        "      j += 1\n",
        "      \n",
        "    H.add_simplex(simplex)    \n",
        "\n",
        "  return H"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbvfs0_8zQi4"
      },
      "source": [
        "def mns(H, s):\n",
        "  if isinstance(H, Hypergraph):\n",
        "    u0, v0 = random.choice(list(H.graph.edges())) \n",
        "  elif isinstance(H, nx.Graph):\n",
        "    u0, v0 = random.choice(list(H.edges()))\n",
        "  f = set([u0, v0])\n",
        "\n",
        "  while len(f) < s:\n",
        "    S = set([])\n",
        "    for u in f:\n",
        "      if isinstance(H, Hypergraph):\n",
        "        for v in H.graph.neighbors(u):\n",
        "          S |= {(u, v)}\n",
        "      elif isinstance(H, nx.Graph):\n",
        "        for v in H.neighbors(u):\n",
        "          S |= {(u, v)}\n",
        "\n",
        "    if len(S) == 0:\n",
        "      return mns(H, s)\n",
        "    else:\n",
        "      u, v = random.choice(list(S))\n",
        "      f |= {u, v}\n",
        "\n",
        "  return f\n",
        "\n",
        "def cns(H, s):\n",
        "  f = set(random.choice(H.simplices).nodes)\n",
        "  v = random.choice(list(f))\n",
        "  \n",
        "  while len(f) < s:\n",
        "    V = set([])\n",
        "    for u in f - {v}:\n",
        "      for smp in H.simplex_neighbors(u):\n",
        "        for w in smp.nodes:  \n",
        "          V |= {w}\n",
        "\n",
        "    if len(V) == 0:\n",
        "      return cns(H, s)\n",
        "    else:\n",
        "      v1 = random.choice(list(V))\n",
        "      f = (f - {v}) | {v1}\n",
        "  return f\n",
        "\n",
        "\n",
        "\n",
        "# Directly sample discrete heights\n",
        "def discrete_tree_sample(b, H, shape=1):\n",
        "  weights = [b**h for h in range(H)]\n",
        "  choices = list(range(H))\n",
        "  return np.array(random.choices(choices, weights, k=shape))\n"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQusJo92bo3p"
      },
      "source": [
        "## CIGAM Model\n",
        "\n",
        "### Bayesian Model\n",
        "\n",
        "We use the following bayesian model in stan \n",
        "\n",
        "\\begin{align}\n",
        "  \\lambda & \\sim \\mathrm{Gamma} (\\alpha, \\beta) \\\\\n",
        "  r(u) | \\lambda & \\sim \\mathrm{TruncExp} (\\lambda, [0, H])  & \\forall u \\in V \\\\\n",
        "  X(u, v) | r(u), r(v) & \\sim \\mathrm{Bern} \\left ( c^{-1-H + \\max \\{ r(u), r(v) \\}} \\right ) & \\forall (u, v) \\in V \\times V\n",
        "\\end{align}\n",
        "\n",
        "The truncated exponential is equivalent to the continuous tree distribution \n",
        "\n",
        "$$p(h(u)) \\propto b^{h(u)} \\mathbf 1 \\{ h(u) \\in [0, H] \\}$$\n",
        "\n",
        "for $h(u) = H - r(u)$ for $\\lambda = \\log b$. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGUhHqeYzr8Z",
        "outputId": "adbb16b0-c0de-426b-8e82-d7f6d7224fee"
      },
      "source": [
        "class CIGAM:\n",
        "\n",
        "  def __init__(self, c=1.5, b=3, H=4):\n",
        "    assert(b > 1)\n",
        "    assert(1 < c < b)\n",
        "\n",
        "    self.c = c\n",
        "    self.H = H\n",
        "    self.lambda_ = np.log(b)\n",
        "    \n",
        "    self.stan_definitions = {\n",
        "        'H' : 'real H;',\n",
        "        'N' : 'int N;',\n",
        "        'b' : 'real<lower=1> b;',\n",
        "        'lambda' : 'real<lower=0> lambda;',\n",
        "        'c' : 'real<lower=1> c;',\n",
        "        'A' : 'int<lower=0, upper=1> A[N, N];',\n",
        "        'heights' : 'real<lower=0, upper=H> heights[N];',\n",
        "        'ranks' : 'real<lower=0, upper=H> ranks[N];'\n",
        "    }\n",
        "\n",
        "  @property\n",
        "  def b(self):\n",
        "    return np.exp(self.lamdba_)\n",
        "\n",
        "  @b.getter\n",
        "  def b(self):\n",
        "    return np.exp(self.lambda_)\n",
        "\n",
        "  @b.setter\n",
        "  def b(self, b_):\n",
        "    self.lambda_ = np.log(b_)\n",
        "    return b_\n",
        "\n",
        "  def sample(self, N, return_ranks=True):\n",
        "    h = self.continuous_tree_sample(N=N)\n",
        "    h = np.sort(h)\n",
        "\n",
        "    G = nx.Graph()\n",
        "\n",
        "    for u in range(N):\n",
        "      G.add_node(u)\n",
        "      for v in range(u):\n",
        "        if u != v and np.random.uniform() <= self.c**(-1-min(h[u], h[v])):\n",
        "          G.add_edge(u, v)\n",
        "       \n",
        "    if return_ranks:\n",
        "      return G, self.H - h\n",
        "    else:\n",
        "      return G, h\n",
        "\n",
        "  def plot_sample(self, n):\n",
        "    G, h = self.sample(n)\n",
        "    A = nx.to_numpy_array(G)\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(A)\n",
        "    plt.title('Adjacency Matrix for G ~ CIGAM($c$={}, $b$={}, $H$={})'.format(self.c, self.b, self.H))\n",
        "    plt.xlabel('Ranked Nodes by $h(u)$')\n",
        "    plt.ylabel('Ranked Nodes by $h(u)$')\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    log_rank = np.log(1 + np.arange(A.shape[0]))\n",
        "    log_degree = np.log(1 + A.sum(0))\n",
        "    log_degree = -np.sort(-log_degree)\n",
        "    p = np.polyfit(log_rank, log_degree, deg=1)\n",
        "    alpha_lasso = 0.1\n",
        "    clf_lasso = linear_model.Lasso(alpha=alpha_lasso)\n",
        "    clf_lasso.fit(log_rank.reshape(-1, 1), log_degree)\n",
        "    r2 = np.corrcoef(log_rank, log_degree)[0, 1]\n",
        "    plt.plot(log_rank, log_degree, linewidth=1, label='Realized Degree $R^2 = {}$'.format(round(r2, 2)))\n",
        "    plt.plot(log_rank, p[1] + p[0] * log_rank, linewidth=2, label='Linear Regression')\n",
        "    plt.plot(log_rank, clf_lasso.intercept_ + clf_lasso.coef_ * log_rank, linewidth=2, label='Lasso Regression ($a = {}$)'.format(alpha_lasso))\n",
        "    plt.xlabel('Node Rank by $h(u)$ (log)')\n",
        "    plt.ylabel('Node Degree (log)')\n",
        "    plt.title('Degree Plot')\n",
        "    plt.legend()\n",
        "\n",
        "  def stan_model(self, known, dump=True, load=True):\n",
        "\n",
        "    model_segment = '''model {\n",
        "\n",
        "      lambda ~ gamma(2, 2);\n",
        "      c ~ pareto(1, 2);\n",
        "\n",
        "      for (i in 1:N) {\n",
        "        ranks[i] ~ exponential(lambda);\n",
        "      }\n",
        "\n",
        "      for (i in 1:N) {\n",
        "        for (j in 1:N) {\n",
        "          if (ranks[i] >= ranks[j]) A[i, j] ~ bernoulli(pow(c, -1-H+ranks[i]));\n",
        "          else A[i, j] ~ bernoulli(pow(c, -1-H+ranks[j]));\n",
        "        }\n",
        "      }\n",
        "}\n",
        "    '''\n",
        "\n",
        "    data = []\n",
        "    params = []\n",
        "    data_keys = []\n",
        "    params_keys = []\n",
        "\n",
        "    for key, val in known.items():\n",
        "      if val:\n",
        "        data.append(self.stan_definitions[key])\n",
        "        data_keys.append(key)\n",
        "      else:\n",
        "        params.append(self.stan_definitions[key])\n",
        "        params_keys.append(key)\n",
        "    \n",
        "    data_text = '\\n\\t'.join(data)\n",
        "    params_text = '\\n\\t'.join(params)\n",
        "\n",
        "    data_segment = 'data {\\n\\t' + data_text + '\\n}'\n",
        "    params_segment = 'parameters {\\n\\t' + params_text + '\\n}'  \n",
        "\n",
        "    model_code = '{}\\n\\n{}\\n\\n{}'.format(data_segment, params_segment, model_segment)\n",
        "\n",
        "    model_name = '{}_given_{}'.format('_'.join(params_keys), '_'.join(data_keys))\n",
        "\n",
        "    if load:\n",
        "      if os.path.isfile('{}.pickle'.format(model_name)):\n",
        "        with open('{}.pickle'.format(model_name), 'rb') as f:\n",
        "          stan_model = pickle.load(f)\n",
        "        return stan_model\n",
        "      else: \n",
        "        stan_model = pystan.StanModel(model_code=model_code, model_name=model_name)\n",
        "    else:\n",
        "      stan_model = pystan.StanModel(model_code=model_code, model_name=model_name)\n",
        "      \n",
        "    if dump:\n",
        "      with open('{}.pickle'.format(model_name), 'wb+') as f:\n",
        "        pickle.dump(stan_model, f, protocol=-1)\n",
        "      with open('{}.stan'.format(model_name), 'w+') as f:\n",
        "        f.write(model_code)\n",
        "\n",
        "    return stan_model\n",
        "\n",
        "  def continuous_tree_sample(self, N):\n",
        "    u = np.random.uniform(size=N)\n",
        "    y = np.log(u * (self.b**self.H - 1) + 1) / np.log(self.b) \n",
        "    return y\n",
        "\n",
        "  def stan_model_sample(self, known, model_data, dump=True, load=True):\n",
        "    stan_model = self.stan_model(known, dump=dump, load=load)\n",
        "    fit = stan_model.sampling(data=model_data, iter=1000, chains=4, seed=1)\n",
        "    return fit\n",
        "\n",
        "  def params_posterior(self):\n",
        "    known = {\n",
        "        'N' : True,\n",
        "        'H' : True,\n",
        "        'A' : True,\n",
        "        'ranks' : True,\n",
        "        'lambda' : False,\n",
        "        'c' : False\n",
        "    }\n",
        "\n",
        "    return known\n",
        "\n",
        "  def latent_posterior(self):\n",
        "    known = {\n",
        "        'N' : True,\n",
        "        'H' : True,\n",
        "        'A' : True,\n",
        "        'ranks' : False,\n",
        "        'lambda' : True,\n",
        "        'c' : True\n",
        "    }\n",
        "\n",
        "    return known\n",
        "\n",
        "  def params_latent_posterior(self):\n",
        "    known = {\n",
        "        'N' : True,\n",
        "        'H' : True,\n",
        "        'A' : True,\n",
        "        'ranks' : False,\n",
        "        'lambda' : False,\n",
        "        'c' : False\n",
        "    }\n",
        "\n",
        "    return known\n",
        "\n",
        "  def visualize_posterior(self, fit, params=None, pairplot=False):\n",
        "\n",
        "    if params is None:\n",
        "      params = list(fit.extract().keys())\n",
        "\n",
        "    if pairplot:\n",
        "      df = stanfit_to_dataframe(fit)\n",
        "      sns.pairplot(df, x_vars=params, y_vars=params, kind='kde')\n",
        "\n",
        "    else:\n",
        "      fig, ax = plt.subplots(figsize=(10, 10))\n",
        "      data = fit.extract()  \n",
        "      colors = iter(cm.rainbow(np.linspace(0, 1, len(params))))\n",
        "\n",
        "      for param in params:\n",
        "        if param == 'lp__':\n",
        "          continue\n",
        "        c = next(colors)\n",
        "        param_mean = round(data[param].mean(), 2)\n",
        "        param_std = round(data[param].std(), 2)\n",
        "        sns.histplot(fit.extract()[param], kde=True, label='{} (mean = {}, std = {})'.format(param, param_mean, param_std), ax=ax, color=c)\n",
        "\n",
        "      plt.xlabel('Parameters')\n",
        "      plt.ylabel('Posterior')\n",
        "      plt.legend()\n",
        "\n",
        "  def fit_model_bayesian_em(self, G, H, lambda_init=np.log(3.2), c_init=1.4, epochs=30):\n",
        "\n",
        "    lambda_old = lambda_init\n",
        "    b_old = np.exp(lambda_old)\n",
        "    c_old = c_init\n",
        "    N = len(G)\n",
        "    A = nx.to_numpy_array(G).astype(np.int64)\n",
        "\n",
        "    optimum = (-np.inf, (lambda_old, b_old, c_old))\n",
        "\n",
        "    for _ in range(epochs):\n",
        "      # E-Step: Sample from p(heights | G, b_old, c_old)\n",
        "      e_data = {\n",
        "          'N' :  N,\n",
        "          'H' : H,\n",
        "          'A' : A,\n",
        "          'lambda' : lambda_old,\n",
        "          'c' : c_old\n",
        "      }\n",
        "\n",
        "      e_fit = cigam.stan_model_sample(cigam.latent_posterior(), e_data)\n",
        "\n",
        "      # For every node let its rank be the mean of the corresponding sampled parameter heights[i]\n",
        "      e_ranks = e_fit.extract()['ranks'].mean(0)\n",
        "\n",
        "      # (Bayesian) M-Step: Sample from p(b, c | G, heights_avg)\n",
        "      m_data = {\n",
        "          'N' : N,\n",
        "          'H' : H,\n",
        "          'A' : A,\n",
        "          'ranks' : e_ranks\n",
        "      }\n",
        "\n",
        "      # Let the parameters of the next iteration be the mean of the predicted parameters\n",
        "      m_fit = cigam.stan_model_sample(cigam.params_posterior(), m_data)\n",
        "      self.lambda_ = m_fit.extract()['lambda'].mean()\n",
        "      self.b = np.exp(m_fit.extract()['lambda']).mean()\n",
        "      self.c = m_fit.extract()['c'].mean()\n",
        "      q_function = CIGAM.q_function(G, e_fit.extract()['ranks'], H, self.b, self.c)\n",
        "\n",
        "      print('lambda = {}, c = {}, b = {}, Q = {}'.format(self.lambda_, self.c, self.b, q_function))\n",
        "\n",
        "      if q_function >= optimum[0]:\n",
        "        optimum = (q_function, (self.lambda_, self.b, self.c))\n",
        "\n",
        "      lambda_old, c_old, b_old = self.lambda_, self.c, self.b\n",
        "\n",
        "    self.lambda_, self.b, self.c = optimum[-1]\n",
        "    print('Best fit', optimum)\n",
        "\n",
        "    return optimum\n",
        "\n",
        "  def fit_model_em(self, G, H, lambda_init=np.log(3.2), c_init=1.4, epochs=30):\n",
        "\n",
        "    lambda_old = lambda_init\n",
        "    b_old = np.exp(lambda_old)\n",
        "    c_old = c_init\n",
        "    N = len(G)\n",
        "    A = nx.to_numpy_array(G).astype(np.int64)\n",
        "\n",
        "    optimum = (-np.inf, (lambda_old, b_old, c_old))\n",
        "\n",
        "    for _ in range(epochs):\n",
        "      # E-Step: Sample from p(heights | G, b_old, c_old)\n",
        "      e_data = {\n",
        "          'N' :  N,\n",
        "          'H' : H,\n",
        "          'A' : A,\n",
        "          'lambda' : lambda_old,\n",
        "          'c' : c_old\n",
        "      }\n",
        "\n",
        "      e_fit = cigam.stan_model_sample(cigam.latent_posterior(), e_data)\n",
        "\n",
        "      m_objective = lambda x: -CIGAM.q_function(G, e_fit.extract()['ranks'], H, x[0], x[1])\n",
        "\n",
        "      res = minimize(m_objective, np.array([np.exp(lambda_old), c_old]), method='BFGS')\n",
        "\n",
        "      self.b = res.x[0]\n",
        "      self.c = res.x[1]\n",
        "      self.lambda_ = np.log(self.b)\n",
        "      q_function = res.fun \n",
        "\n",
        "      print('lambda = {}, c = {}, b = {}, Q = {}'.format(self.lambda_, self.c, self.b, q_function))\n",
        "\n",
        "      if q_function >= optimum[0]:\n",
        "        optimum = (q_function, (self.lambda_, self.b, self.c))\n",
        "\n",
        "      lambda_old, c_old, b_old = self.lambda_, self.c, self.b\n",
        "\n",
        "    self.lambda_, self.b, self.c = optimum[-1]\n",
        "    print('Best fit', optimum)\n",
        "\n",
        "    return optimum\n",
        "\n",
        "  def fit_model_bayesian(self, G, H):\n",
        "    data = {\n",
        "        'N' : len(G),\n",
        "        'H' : H,\n",
        "        'A' : nx.to_numpy_array(G).astype(np.int64)\n",
        "    }\n",
        "\n",
        "    fit = cigam.stan_model_sample(cigam.params_latent_posterior(), data)\n",
        "    self.lambda_ = fit.extract()['lambda'].mean()\n",
        "    self.b = np.exp(fit.extract()['lambda']).mean()\n",
        "    self.c = fit.extract()['c'].mean()\n",
        "    self.H = H\n",
        "\n",
        "    return fit\n",
        "\n",
        "  @staticmethod\n",
        "  def ranks_log_likelihood(ranks, H, b):\n",
        "    result = 0\n",
        "    heights = H - ranks\n",
        "    for h in heights:\n",
        "      result += (np.log(np.log(b)) - np.log(b**H - 1) + h * np.log(b))\n",
        "\n",
        "    return result\n",
        "\n",
        "  @staticmethod\n",
        "  def graph_log_likelihood(G, ranks, H, c):\n",
        "    heights = H - ranks\n",
        "    result = 0\n",
        "    for u in G:\n",
        "      for v in G:\n",
        "        if u != v:\n",
        "          if G.has_edge(u, v):\n",
        "            result += np.log(c**(-1 - min(heights[u], heights[v])))\n",
        "          else:\n",
        "            result += np.log(1 - c**(-1 - min(heights[u], heights[v])))\n",
        "    return result\n",
        "\n",
        "  @staticmethod\n",
        "  def complete_log_likelihood(G, ranks, H, b, c):\n",
        "    return CIGAM.ranks_log_likelihood(ranks, H, b) + CIGAM.graph_log_likelihood(G, ranks, H, c)\n",
        "\n",
        "  @staticmethod\n",
        "  def q_function(G, ranks_post, H, b, c):\n",
        "    return np.mean([CIGAM.complete_log_likelihood(G, ranks_post[i, :], H, b, c) for i in range(ranks_post.shape[0])])\n",
        "\n",
        "cigam = CIGAM()\n",
        "\n",
        "cigam.plot_sample(1000)\n",
        "\n",
        "fit = cigam.fit_model_bayesian(load_world_trade(), 5)\n",
        "cigam.visualize_posterior(fit, ['lambda', 'c'], pairplot=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:pystan:COMPILING THE C++ CODE FOR MODEL ranks_lambda_c_given_N_H_A_c9c63431265908d1e104fe6d175f53c0 NOW.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7j7SjI-pbsIq"
      },
      "source": [
        "## (Bayesian) Logistic-CP Model (Jia & Benson)\n",
        "\n",
        "We also sample from a Bayesian version of the Logistic-CP model from Jia and Benson, based on the following Bayesian model \n",
        "\n",
        "\\begin{align}\n",
        "  X(u) & \\sim \\mathrm{Beta}(\\alpha, \\beta) & \\forall u \\in V \\\\\n",
        "  Z(u) & \\sim \\mathrm{Exp}(\\lambda) & \\forall u \\in V \\\\\n",
        "  \\theta(u) &  = (2X(u) - 1) Z(u) & \\forall u \\in V \\\\\n",
        "  X(u, v) | \\theta(u), \\theta(v) & \\sim \\mathrm{Bern} \\left ( \\sigma (\\theta(u) + \\theta(v) ) \\right ) & \\forall (u, v) \\in V \\times V\n",
        "\\end{align}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4M8Hq6PacEYw"
      },
      "source": [
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "class LogisticCP:\n",
        "\n",
        "  def __init__(self, lambda_=1, alpha=2, beta=2):\n",
        "    self.lambda_ = lambda_\n",
        "    self.alpha = alpha\n",
        "    self.beta = beta\n",
        "\n",
        "    self.stan_definitions = {\n",
        "        'N' : 'int N;',\n",
        "        'A' : 'int<lower=0, upper=1> A[N, N];',\n",
        "        'alpha' : 'real<lower=0> alpha;',\n",
        "        'beta' : 'real<lower=0> beta;',\n",
        "        'lambda' : 'real<lower=0> lambda;',\n",
        "        'coins' : 'real<lower=0, upper=1> coins[N];',\n",
        "        'intermediate_thetas' : 'real<lower=0> intermediate_thetas[N];'\n",
        "    }\n",
        "\n",
        "  @property\n",
        "  def mu(self):\n",
        "    return 1 / self.lambda_\n",
        "\n",
        "  @mu.getter\n",
        "  def mu(self):\n",
        "    return 1 / self.lambda_\n",
        "\n",
        "  @mu.setter\n",
        "  def mu(self, mu_):\n",
        "    assert(mu_ > 0)\n",
        "    self.lambda_ = 1 / mu_\n",
        "\n",
        "  def sample(self, n):\n",
        "    # thetas = -np.sort(-np.random.normal(loc=self.mu, scale=self.sigma, size=n))\n",
        "    coins = np.random.beta(self.alpha, self.beta, size=n)\n",
        "    intermediate_thetas = np.random.exponential(scale=1 / self.lambda_, size=n)\n",
        "    thetas = - np.sort(-(2 * coins - 1) * intermediate_thetas)\n",
        "\n",
        "    G = nx.Graph()\n",
        "\n",
        "    for u in range(n):\n",
        "      G.add_node(u)\n",
        "      for v in range(u):\n",
        "        if u != v and np.random.uniform() <= sigmoid(thetas[u] + thetas[v]):\n",
        "          G.add_edge(u, v)\n",
        "\n",
        "    return G, coins, intermediate_thetas, thetas\n",
        "\n",
        "  def plot_sample(self, n):\n",
        "    G, coins, thetas = self.sample(n)\n",
        "    A = nx.to_numpy_array(G)\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(A)\n",
        "    plt.title('Adjacency Matrix for G ~ logstic-CP($\\mu$={}, $a$={}, $b$={})'.format(self.mu, self.alpha, self.beta))\n",
        "    plt.xlabel('Ranked Nodes by $\\\\theta(u)$')\n",
        "    plt.ylabel('Ranked Nodes by $\\\\theta(u)$')\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    log_rank = np.log(1 + np.arange(A.shape[0]))\n",
        "    log_degree = np.log(1 + A.sum(0))\n",
        "    plt.plot(log_rank, log_degree)\n",
        "    plt.title('Degree Plot')\n",
        "    plt.xlabel('Node Rank by $\\\\theta(u)$ (log)')\n",
        "    plt.ylabel('Node Degree (log)')\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    degree_ranks = np.argsort(-log_degree)\n",
        "    for i in range(A.shape[0]):\n",
        "      A[i, :] = A[i, degree_ranks]\n",
        "\n",
        "    for i in range(A.shape[1]):\n",
        "      A[:, i] = A[degree_ranks, i]\n",
        "\n",
        "    log_degree = log_degree[degree_ranks]\n",
        "    plt.imshow(A)\n",
        "    plt.title('Adjacency Matrix for G ~ logstic-CP($\\mu$={}, $a$={}, $b$={})'.format(self.mu, self.alpha, self.beta))\n",
        "    plt.xlabel('Ranked Nodes by degree')\n",
        "    plt.ylabel('Ranked Nodes by degree')\n",
        "    plt.figure(figsize=(10, 10))\n",
        "\n",
        "    plt.plot(log_rank, log_degree)\n",
        "    p = np.polyfit(log_rank, log_degree, deg=1)\n",
        "    alpha_lasso = 0.1\n",
        "    clf_lasso = linear_model.Lasso(alpha=alpha_lasso)\n",
        "    clf_lasso.fit(log_rank.reshape(-1, 1), log_degree)\n",
        "    r2 = np.corrcoef(log_rank, log_degree)[0, 1]\n",
        "    plt.plot(log_rank, log_degree, linewidth=1, label='Realized Degree $R^2 = {}$'.format(round(r2, 2)))\n",
        "    plt.plot(log_rank, p[1] + p[0] * log_rank, linewidth=2, label='Linear Regression')\n",
        "    plt.plot(log_rank, clf_lasso.intercept_ + clf_lasso.coef_ * log_rank, linewidth=2, label='Lasso Regression ($a = {}$)'.format(alpha_lasso))\n",
        "    plt.title('Degree Plot')\n",
        "    plt.xlabel('Node Rank by degree (log)')\n",
        "    plt.ylabel('Node Degree (log)')\n",
        "    plt.legend()\n",
        "\n",
        "  def stan_model(self, known, dump=True, load=True):\n",
        "\n",
        "    functions_segment = '''functions {\n",
        "      real sigmoid(real x) {\n",
        "        return 1 / (1 + exp(-x));\n",
        "      }\n",
        "}'''\n",
        "\n",
        "    model_segment = '''model {\n",
        "      lambda ~ gamma(2, 2);\n",
        "      alpha ~ lognormal(0, 1);\n",
        "      beta ~ lognormal(0, 1);\n",
        "\n",
        "      for (i in 1:N) {\n",
        "        coins[i] ~ beta(alpha, beta);\n",
        "        intermediate_thetas[i] ~ exponential(lambda);\n",
        "      }\n",
        "\n",
        "      for (i in 1:N) {\n",
        "        for (j in 1:N) {\n",
        "          A[i, j] ~ bernoulli(sigmoid((2 * coins[i] - 1) * intermediate_thetas[i] + (2 * coins[j] - 1) * intermediate_thetas[j]));\n",
        "        }\n",
        "      }\n",
        "}\n",
        "    '''\n",
        "\n",
        "    data = []\n",
        "    params = []\n",
        "    data_keys = []\n",
        "    params_keys = []\n",
        "\n",
        "    for key, val in known.items():\n",
        "      if val:\n",
        "        data.append(self.stan_definitions[key])\n",
        "        data_keys.append(key)\n",
        "      else:\n",
        "        params.append(self.stan_definitions[key])\n",
        "        params_keys.append(key)\n",
        "    \n",
        "    data_text = '\\n\\t'.join(data)\n",
        "    params_text = '\\n\\t'.join(params)\n",
        "\n",
        "    data_segment = 'data {\\n\\t' + data_text + '\\n}'\n",
        "    params_segment = 'parameters {\\n\\t' + params_text + '\\n}'  \n",
        "\n",
        "    model_code = '{}\\n\\n{}\\n\\n{}\\n\\n{}'.format(functions_segment, data_segment, params_segment, model_segment)\n",
        "\n",
        "    model_name = '{}_given_{}'.format('_'.join(params_keys), '_'.join(data_keys))\n",
        "\n",
        "    if load:\n",
        "      if os.path.isfile('{}.pickle'.format(model_name)):\n",
        "        with open('{}.pickle'.format(model_name), 'rb') as f:\n",
        "          stan_model = pickle.load(f)\n",
        "        return stan_model\n",
        "      else: \n",
        "        stan_model = pystan.StanModel(model_code=model_code, model_name=model_name)\n",
        "    else:\n",
        "      stan_model = pystan.StanModel(model_code=model_code, model_name=model_name)\n",
        "      \n",
        "    if dump:\n",
        "      with open('{}.pickle'.format(model_name), 'wb+') as f:\n",
        "        pickle.dump(stan_model, f, protocol=-1)\n",
        "      with open('{}.stan'.format(model_name), 'w+') as f:\n",
        "        f.write(model_code)\n",
        "\n",
        "    return stan_model\n",
        "\n",
        "  def stan_model_sample(self, known, model_data, dump=True, load=True):\n",
        "    stan_model = self.stan_model(known, dump=dump, load=load)\n",
        "    fit = stan_model.sampling(data=model_data, iter=1000, chains=4, seed=1)\n",
        "    return fit\n",
        "\n",
        "  def params_posterior(self):\n",
        "    known = {\n",
        "        'N' : True, \n",
        "        'A' : True,\n",
        "        'coins' : True, \n",
        "        'intermediate_thetas' : True,\n",
        "        'alpha' : False,\n",
        "        'beta' : False,\n",
        "        'lambda' : False\n",
        "    }\n",
        "\n",
        "    return known\n",
        "\n",
        "  def latent_posterior(self):\n",
        "    known = {\n",
        "        'N' : True, \n",
        "        'A' : True,\n",
        "        'coins' : False, \n",
        "        'intermediate_thetas' : False,\n",
        "        'alpha' : True,\n",
        "        'beta' : True,\n",
        "        'lambda' : True\n",
        "    }\n",
        "\n",
        "    return known\n",
        "\n",
        "  def params_latent_posterior(self):\n",
        "    known = {\n",
        "        'N' : True, \n",
        "        'A' : True,\n",
        "        'coins' : False, \n",
        "        'intermediate_thetas' : False,\n",
        "        'alpha' : False,\n",
        "        'beta' : False,\n",
        "        'lambda' : False\n",
        "    }\n",
        "\n",
        "    return known\n",
        "\n",
        "  def visualize_posterior(self, fit, params=None, pairplot=False):\n",
        "\n",
        "    if params is None:\n",
        "      params = list(fit.extract().keys())\n",
        "\n",
        "    if pairplot:\n",
        "      df = stanfit_to_dataframe(fit)\n",
        "      sns.pairplot(df, x_vars=params, y_vars=params, kind='kde')\n",
        "      \n",
        "    else:\n",
        "      fig, ax = plt.subplots(figsize=(10, 10))\n",
        "      data = fit.extract()  \n",
        "      colors = iter(cm.rainbow(np.linspace(0, 1, len(params))))\n",
        "\n",
        "      for param in params:\n",
        "        if param == 'lp__':\n",
        "          continue\n",
        "        c = next(colors)\n",
        "        param_mean = round(data[param].mean(), 2)\n",
        "        param_std = round(data[param].std(), 2)\n",
        "        sns.histplot(fit.extract()[param], kde=True, label='{} (mean = {}, std = {})'.format(param, param_mean, param_std), ax=ax, color=c)\n",
        "\n",
        "      plt.xlabel('Parameters')\n",
        "      plt.ylabel('Posterior')\n",
        "      plt.legend()\n",
        "\n",
        "logistic_cp = LogisticCP(lambda_=1/3, alpha=1, beta=4)\n",
        "\n",
        "G, coins, intermediate_thetas, thetas = logistic_cp.sample(50)\n",
        "\n",
        "data = {\n",
        "    'N' : len(G),\n",
        "    'A' : nx.to_numpy_array(G).astype(np.int64),\n",
        "    # 'alpha' : 1,\n",
        "    # 'beta' : 4,\n",
        "    # 'lambda' : 1/3\n",
        "    'coins' : coins,\n",
        "    'intermediate_thetas' : intermediate_thetas\n",
        "}\n",
        "\n",
        "fit = logistic_cp.stan_model_sample(logistic_cp.params_posterior(), model_data=data)\n",
        "\n",
        "logistic_cp.visualize_posterior(fit, params=['alpha', 'beta', 'lambda'], pairplot=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoKWHDCo0ap2"
      },
      "source": [
        "def generalized_mean(x, p):\n",
        "  if np.isinf(p):\n",
        "    return np.max(x)\n",
        "  elif np.isinf(-p):\n",
        "    return np.min(x)\n",
        "  else:\n",
        "    return np.linalg.norm(x) / len(x)**(1 / p)\n",
        "\n",
        "class LogisticTH:\n",
        "\n",
        "  def __init__(self, p=20):\n",
        "    self.p = p\n",
        "  \n",
        "  def sample(self, n):\n",
        "    G = nx.Graph()\n",
        "\n",
        "    ranks = n - (1 + np.arange(n))\n",
        "\n",
        "    for u in range(n):\n",
        "      G.add_node(u)\n",
        "      for v in range(u):\n",
        "        if u != v and np.random.uniform() <= sigmoid(generalized_mean([ranks[u], ranks[v]], self.p) / n):\n",
        "          G.add_edge(u, v)\n",
        "\n",
        "    return G, ranks\n",
        "\n",
        "  def display_p(self):\n",
        "    if np.isinf(self.p):\n",
        "      return '\\\\infty'\n",
        "    elif np.isinf(-self.p):\n",
        "      return '- \\\\infty'\n",
        "    else:\n",
        "      return self.p\n",
        "\n",
        "  def plot_sample(self, n):\n",
        "    G, ranks = self.sample(n)\n",
        "    A = nx.to_numpy_array(G)\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(A)\n",
        "    plt.title('Adjacency Matrix for G ~ logstic-TH($p={}$)'.format(self.display_p()))\n",
        "    plt.xlabel('Ranked Nodes by $\\\\pi(u)$')\n",
        "    plt.ylabel('Ranked Nodes by $\\\\pi(u)$')\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    log_rank = np.log(1 + np.arange(A.shape[0]))\n",
        "    log_degree = np.log(1 + A.sum(0))\n",
        "    plt.plot(log_rank, log_degree)\n",
        "    plt.title('Degree Plot')\n",
        "    plt.xlabel('Node Rank by $\\\\pi(u)$ (log)')\n",
        "    plt.ylabel('Node Degree (log)')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    degree_ranks = np.argsort(-log_degree)\n",
        "    for i in range(A.shape[0]):\n",
        "      A[i, :] = A[i, degree_ranks]\n",
        "\n",
        "    for i in range(A.shape[1]):\n",
        "      A[:, i] = A[degree_ranks, i]\n",
        "\n",
        "    log_degree = log_degree[degree_ranks]\n",
        "    plt.imshow(A)\n",
        "    plt.title('Adjacency Matrix for G ~ logstic-TH($p={}$)'.format(self.display_p()))\n",
        "    plt.xlabel('Ranked Nodes by degree')\n",
        "    plt.ylabel('Ranked Nodes by degree')\n",
        "    plt.figure(figsize=(10, 10))\n",
        "\n",
        "    plt.plot(log_rank, log_degree)\n",
        "    p = np.polyfit(log_rank, log_degree, deg=1)\n",
        "    alpha_lasso = 0.1\n",
        "    clf_lasso = linear_model.Lasso(alpha=alpha_lasso)\n",
        "    clf_lasso.fit(log_rank.reshape(-1, 1), log_degree)\n",
        "    r2 = np.corrcoef(log_rank, log_degree)[0, 1]\n",
        "    plt.plot(log_rank, log_degree, linewidth=1, label='Realized Degree $R^2 = {}$'.format(round(r2, 2)))\n",
        "    plt.plot(log_rank, p[1] + p[0] * log_rank, linewidth=2, label='Linear Regression')\n",
        "    plt.plot(log_rank, clf_lasso.intercept_ + clf_lasso.coef_ * log_rank, linewidth=2, label='Lasso Regression ($a = {}$)'.format(alpha_lasso))\n",
        "    plt.title('Degree Plot')\n",
        "    plt.xlabel('Node Rank by degree (log)')\n",
        "    plt.ylabel('Node Degree (log)')\n",
        "    plt.legend()\n",
        "\n",
        "  def fit(self, G, alpha=10):\n",
        "    q = self.p / (self.p - 1)\n",
        "    n = len(G)\n",
        "\n",
        "    def helper(x, G, alpha):\n",
        "      F = np.zeros_like(x)\n",
        "\n",
        "      for i in G:\n",
        "        for j in G.neighbors(i):\n",
        "          F[i] += np.abs(x[i])**(alpha - 2) * x[i] * (x[i]**alpha + x[j]**alpha) ** (1 / (alpha) - 1)\n",
        "\n",
        "      return F\n",
        "\n",
        "    x = np.ones(shape=n)\n",
        "    y = np.ones(shape=n)\n",
        "\n",
        "    x_prev = x\n",
        "\n",
        "    for i in range(100):\n",
        "      y = helper(x, G, alpha)\n",
        "      x = np.linalg.norm(y, q)**(q - 1) * np.abs(y)**(q - 2) * y\n",
        "      if np.allclose(x, x_prev):\n",
        "        break\n",
        "      else:\n",
        "        x_prev = x\n",
        "\n",
        "    ranks = np.argsort(-x)[::-1]\n",
        "\n",
        "    return x, ranks"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ds2ifDR5rPzn"
      },
      "source": [
        "## Sampling Hypergraphs \n",
        "\n",
        "### Grass-hopping Helper Functions\n",
        "\n",
        "Below we define the following command to sample hyperedges of the following form:\n",
        "\n",
        "1. We are given a ground set $S$ of nodes that must belong to the hyperedge and a number $k > |S|$ that indicates the size of the hyperedges. \n",
        "2. We are given a probability $p \\in (0, 1)$ such that each hyperedge is generated with probability $p$.\n",
        "3. We are given a set $Q$ from which the other vertices of the hyperedge are sampled upon. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gui1SRX9s_iF"
      },
      "source": [
        "def int2base(x, base):\n",
        "    digits = []\n",
        "\n",
        "    while x:\n",
        "        digits.append(x % base)\n",
        "        x //= base\n",
        "\n",
        "    return digits\n",
        "\n",
        "def grass_hopping_helper(S, V, k, p, directed=True):\n",
        "  assert(k > len(S))\n",
        "  n = len(V)\n",
        "  s = len(S)\n",
        "  i = -1\n",
        "\n",
        "  edges = set()\n",
        "\n",
        "  q = p\n",
        "\n",
        "  while True: \n",
        "    i += np.random.geometric(q)\n",
        "    decoded = int2base(i, n)\n",
        "\n",
        "    if len(decoded) > k - s:\n",
        "      break\n",
        "    else:\n",
        "      simplex = tuple(S + [V[int(j)] for j in decoded])\n",
        "      # Perform rejection sampling if the graph is undirected\n",
        "      if directed or ((not directed) and decoded == list(sorted(decoded))):\n",
        "        edges.add(simplex)\n",
        "    \n",
        "  return edges\n",
        "\n",
        "def sample_combination(n, k):\n",
        "  S = set([])\n",
        "\n",
        "  # Generate combinations uniformly with rejection sampling\n",
        "  while len(S) < k:\n",
        "    u = np.random.randint(low=0, high=n-1)\n",
        "    if u not in S:\n",
        "      S |= {u}\n",
        "\n",
        "  return list(S)        \n",
        "\n",
        "def ball_dropping_helper(S, V, k, p, directed=True):\n",
        "    assert(k > len(S))\n",
        "    n = len(V)\n",
        "    s = len(S)\n",
        "\n",
        "    if directed:\n",
        "      m = int(np.random.binomial(n**(k - s), p))   \n",
        "    else:\n",
        "      m = int(np.random.binomial(special.comb(n, k - s), p))\n",
        "\n",
        "    edges = set()                           \n",
        "    while len(edges) < m:\n",
        "        if directed:\n",
        "          e_index = np.random.randint(low=0, high=n, size=k-s)\n",
        "        else:\n",
        "          e_index = sample_combination(n, k - s)\n",
        "        e = tuple(S + [V[idx] for idx in e_index])\n",
        "        if e not in edges:                  \n",
        "            edges.add(e)                    \n",
        "    return list(edges)                      \n",
        "\n",
        "n = 100\n",
        "p = 0.6\n",
        "k = 4\n",
        "S = [0]\n",
        "V = list(range(1, n))\n",
        "s = len(S)\n",
        "print('Ball dropping')\n",
        "%timeit ball_dropping_helper(S, V, k, p, directed=False)\n",
        "# print('Grass hopping')\n",
        "# %timeit grass_hopping_helper(S, V, k, p, directed=False)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nvEc7o528fHd"
      },
      "source": [
        "class CIGAMHyper:\n",
        "  def __init__(self, b=3, c=1.5, H=4, order=3):\n",
        "    self.b = b\n",
        "    self.c = c\n",
        "    self.H = H\n",
        "    self.order = order\n",
        "\n",
        "  def sample(self, N, return_ranks=True):\n",
        "    h = self.continuous_tree_sample(N=N)\n",
        "    ranks = np.argsort(h)\n",
        "    h = h[ranks]\n",
        "    H = Hypergraph()\n",
        "\n",
        "    for i in range(ranks.shape[0] - self.order):\n",
        "      batch = ball_dropping_helper(S=[ranks[i]], V=ranks[i+1:], p=self.c**(-1-h[i]), k=self.order, directed=False)\n",
        "       \n",
        "      for edge in batch:\n",
        "        H.add_simplex_from_nodes(nodes=edge, timestamp=None)\n",
        "\n",
        "    if return_ranks:\n",
        "      return H, self.H - h\n",
        "    else:\n",
        "      return H, h\n",
        "\n",
        "  def continuous_tree_sample(self, N):\n",
        "    u = np.random.uniform(size=N)\n",
        "    y = np.log(u * (self.b**self.H - 1) + 1) / np.log(self.b) \n",
        "    return y\n",
        "\n",
        "\n",
        "  def plot_sample(self, n):\n",
        "    assert(self.order == 2)\n",
        "    H, h = self.sample(n)\n",
        "    G = H.clique_decomposition()\n",
        "    A = nx.to_numpy_array(G)\n",
        "\n",
        "    degree_ranks = np.argsort(-A.sum(0))\n",
        "  \n",
        "    for i in range(A.shape[0]):\n",
        "      A[i, :] = A[i, degree_ranks]\n",
        "\n",
        "    for i in range(A.shape[1]):\n",
        "      A[:, i] = A[degree_ranks, i]\n",
        "\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(A)\n",
        "    plt.title('Adjacency Matrix for G ~ CIGAM($c$={}, $b$={}, $H$={}) (w/ ball dropping)'.format(self.c, self.b, self.H))\n",
        "    plt.xlabel('Ranked Nodes by $h(u)$')\n",
        "    plt.ylabel('Ranked Nodes by $h(u)$')\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    log_rank = np.log(1 + np.arange(A.shape[0]))\n",
        "    log_degree = np.log(1 + A.sum(0))\n",
        "    log_degree = -np.sort(-log_degree)\n",
        "    p = np.polyfit(log_rank, log_degree, deg=1)\n",
        "    alpha_lasso = 0.1\n",
        "    clf_lasso = linear_model.Lasso(alpha=alpha_lasso)\n",
        "    clf_lasso.fit(log_rank.reshape(-1, 1), log_degree)\n",
        "    r2 = np.corrcoef(log_rank, log_degree)[0, 1]\n",
        "    plt.plot(log_rank, log_degree, linewidth=1, label='Realized Degree $R^2 = {}$'.format(round(r2, 2)))\n",
        "    plt.plot(log_rank, p[1] + p[0] * log_rank, linewidth=2, label='Linear Regression')\n",
        "    plt.plot(log_rank, clf_lasso.intercept_ + clf_lasso.coef_ * log_rank, linewidth=2, label='Lasso Regression ($a = {}$)'.format(alpha_lasso))\n",
        "    plt.xlabel('Node Rank by $h(u)$ (log)')\n",
        "    plt.ylabel('Node Degree (log)')\n",
        "    plt.title('Degree Plot')\n",
        "    plt.legend()\n",
        "\n",
        "# Plot a 2-order-hypergraph (i.e. graph) with the ball-dropping technique\n",
        "cigam_hyper = CIGAMHyper(order=2)\n",
        "cigam_hyper.plot_sample(1000)\n",
        "\n",
        "# Plot a graph with naive sampling\n",
        "cigam = CIGAM()\n",
        "cigam.plot_sample(1000)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}